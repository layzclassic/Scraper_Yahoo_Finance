from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import NoSuchElementException
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import re
import spacy

# collection of words from each post
bullish_doc = []
bearish_doc = []
neutral_doc = []
# sentiment number count
bullish = {'Bullish': '', 'Upvotes': '', 'Downvotes': ''}
bearish = {'Bearish': '', 'Upvotes': '', 'Downvotes': ''}
neutral = {'Neutral': '', 'Upvotes': '', 'Downvotes': ''}
tweet_id = set()
sentiment = '//*[@id="canvass-0-CanvassApplet"]/div/ul/li/div/div[3]/div/div/svg'
reply = '//span[contains(text(),"Reply")]'
upvote = '//*[@id="canvass-0-CanvassApplet"]/div/ul/li/div/div[5]/div[2]/button[1]'
downvote = '//*[@id="canvass-0-CanvassApplet"]/div/ul/li/div/div[5]/div[2]/button[2]'

def main(ticker):
    # create instance of web driver
    site = web_driver(ticker)
    # choose filter method in drop down list
    selectReaction()
    scrape_post()

def selectReaction():
    clickByText('Top Reactions')
    clickByText('Newest Reactions')
    sleep(5)

def clickByText(text):
    driver.find_elements(By.XPATH, '//span[contains(text(),"' + text + '")]')[0].click()

def sentiment_identifier():

def scrape_numbers():
    upvote = driver.find_element( By.XPATH, '//*[@id="canvass-0-CanvassApplet"]/div/div   )
    downvote =
    replies =

def scrape_loop():
    posts = driver.find_element( By.XPATH, '//*[@id="canvass-0-CanvassApplet"]')
    for post in posts[]:
        content = scrape_numbers()
        if :
            poster_id = ''.join(content)
            # keep track of tweets already scraped by turning tweet into a string idenifier
            if poster_id not in poster_ids:
                poster_ids.add(poster_id)
                .append(content)

def web_driver(ticker):
    global driver
    driver_path = 'C:/Users/suen6/.wdm/drivers/chromedriver/win32/98.0.4758.80/chromedriver.exe'
    driver = webdriver.Chrome(executable_path=driver_path, options=build_chrome_options())
    driver.header = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.82 Safari/537.36"}
    url ='https://finance.yahoo.com/quote/{}/community?p={}'.format(ticker, ticker)
    response = driver.get(url)
    return response

def build_chrome_options():
    chrome_options = webdriver.ChromeOptions()
    chrome_options.accept_untrusted_certs = True
    chrome_options.assume_untrusted_cert_issuer = True
    chrome_options.add_argument("incognito")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--window-size=1024,800")
    chrome_options.add_argument("disable-extensions")
    chrome_options.add_argument("--start-maximized")
    chrome_options.add_argument("--test-type=browser")
    chrome_options.add_argument("--disable-impl-side-painting")
    chrome_options.add_argument("--disable-setuid-sandbox")
    chrome_options.add_argument("--disable-seccomp-filter-sandbox")
    chrome_options.add_argument("--disable-breakpad")
    chrome_options.add_argument("--disable-client-side-phishing-detection")
    chrome_options.add_argument("--disable-cast")
    chrome_options.add_argument("--disable-cast-streaming-hw-encoding")
    chrome_options.add_argument("--disable-cloud-import")
    chrome_options.add_argument("--disable-popup-blocking")
    chrome_options.add_argument("--ignore-certificate-errors")
    chrome_options.add_argument("--disable-session-crashed-bubble")
    chrome_options.add_argument("--disable-ipv6")
    chrome_options.add_argument("--allow-http-screen-capture")
    return chrome_options

if __name__ == '__main__':
    ticker = 'WISH'
    main(ticker)
